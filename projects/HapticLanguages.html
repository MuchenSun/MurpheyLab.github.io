---
layout: project
title: Haptic Languages
---

<h1>Haptic Languages</h1>

<body>
	<div class="row" style="margin-bottom=-1em; margin-left:0.2em">
		<div class="container">
			<img style="width:100%" src="/images/ShapeLearning.jpg" alt="Shape Learning">
			<div class="caption" style="width:95%; bottom:1.5%;"><p>Shape estimation using binary sensing and ergodic exploration</p></div>
		</div>
	</div>

	<br><p>We are interested in how robots can construct symbolic representations from mechanical contact.  For instance, how can a robot feel an object with fingertip sensors and generate a symbolic representation of that object that is rich enough to identify the object in the future? How the robot runs the fingertip over the object will greatly influence the representation it gets, so determining control laws from the learning need is a major part of this research.  In the image above, we focused on enabling a robot to determine the shape of an object by interacting with it and measuring only its end effector kinematics.  Over a short amount of time, the shape stabilizes to a fixed representation that can then be used in the future for searching for the object. Goals of this work include the following.

	  <ul class="list">
	   <p>&bull; determine algorithms for actively exploring a region to determine multiple shapes of multiple objects.</p>
	   <p>&bull; determine algorithms that can use individual representations of objects to identify and localize an object.</p>
	   <p>&bull; determine other symbolic representations beyond shape, such as texture, that can be used for touch-based discrimination.</p>
	 </ul></p>

	<h3>People</h3>
	<p><a href="/people/ianabraham">Ian Abraham</a> (Ph.D. Student)
		<br><a href="/people/ahalyaprabhakar">Ahalya Prabhakar</a> (Ph.D. Student)</p>

	<h3>Collaborators</h3>
	<p><a href="http://hartmann.mech.northwestern.edu/">Mitra Hartmann</a>, Northwestern University</p>

	<h3>Publications</h3>
	<p><b>Real-time area coverage and target localization using receding-horizon ergodic exploration</b>
	  <br>A. Mavrommati, E. Tzorakoleftherakis, I. Abraham, and T. D. Murphey
	  <br><i>IEEE Transactions on Robotics</i>, vol. 34, no. 1, pp. 62–80, 2018. <a href="pdfs/2018TROMaTzAbMu.pdf">PDF</a>,  <a href="videos/2018TROMaTzAbMuExplorationVideos.mp4">Video 1</a>,  <a href="videos/2018TROMaTzAbMuLocalizationVideos.mp4">Video 2</a></p>
	<p><b>Data-driven measurement models for active localization in sparse environments</b>
	  <br>I. Abraham, A. Mavrommati, and T. D. Murphey
	  <br><i>Robotics: Science and Systems Proceedings</i>, 2018. <a href="pdfs/2018RSSAbMaMu.pdf">PDF</a>, <a href="videos/2018RSSAbMaMu.mp4">Video</a></p>
	<p><b>Ergodic exploration using binary sensing for non-parametric shape estimation</b>
	  <br>I. Abraham, A. Prabhakar, M. Hartmann, and T. Murphey
	  <br><i>IEEE Robotics and Automation Letters</i>, vol. 2, no. 2, pp. 827–834, 2017. <a href="pdfs/2017RALAbPrHaMu.pdf">PDF</a>, <a href="videos
	  /2017RALAbPrHaMu.mp4">Video</a></p>
	<p><b>Autonomous visual rendering using physical motion</b>
	  <br>A. Prabhakar, A. Mavrommati, J. Schultz, and T. D. Murphey
	  <br><i>Workshop on the Algorithmic Foundations of Robotics (WAFR)</i>, 2016. <a href="pdfs/2016WAFRPrMaScMu.pdf">PDF</a>, <a href="videos/2016WAFRPrMaScMuBaxterLincoln.mp4">Video 1</a>,  <a href="videos/2016WAFRPrMaScMuLincolnSim.mp4">Video 2</a>, <a href="videos/2016WAFRPrMaScMuNSim.mp4">Video 3</a> </p>

	<h3>Funding</h3>
	<p>This project is funded by the National Science Foundation–National Robotics Initiative: Autonomous Synthesis of Haptic Languages.</p><br>

</body>
