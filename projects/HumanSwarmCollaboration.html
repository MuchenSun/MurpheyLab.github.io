---
layout: project
title: Human-Swarm Collaboration
---

<h1>Active Perception in Human-Swarm Collaboration</h1>

<body>

	<!-- <video width=100% controls muted id="vid1">
       <source src="/videos/22018TROMaTzAbMuLocalizationVideos_CROPPED_RESIZED.mp4" type="video/mp4" />
   </video> -->

	<div class="row" style="margin-bottom=-1em; margin-left:0.2em">
		<div class="column2" style="width:45.5%">
			<img style="width:100%;" src="/images/HumanSwarm.jpg" alt="Human-Swarm Collaboration" title="Human-swarm collaboration in an urban environment">
		</div>
		<div class="column2" style="width:53.5%">
			<video width=100% controls muted>
					 <source src="/videos/2018TROMaTzAbMuLocalizationVideos_CROPPED_RESIZED.mp4" type="video/mp4">
			 </video>
		</div>
	</div>

	<br>
	<p>We are interested in improving human-swarm team performance by including
	the human directly into the control loop. While fully autonomous robotic
	exploration requires less supervision, it neglects the operator’s intuition.
	We have developed a shared control algorithm that leverages the capabilities
	of the human and the swarm by. This project focuses on determining how
	autonomy allocation affects exploration efforts, thus task performance of the
	human-swarm collaboration.

	Ongoing efforts utilize virtual reality (VR) environment build in Unity Software
	and HTC VIVE headset before transferring to field tests. At the same time, we
	are collecting biometric data such as eye gaze (Pupil Labs), EEG (Emotiv) and
	EKG (SOMNOmedics) to determine operator’s cognitive state. </p>

	<h3>People</h3>
	<p><a href="/people/thomasberrueta">Thomas Berrueta</a> (Ph.D. Student)
		<br><a href="/people/katarinapopovic">Katarina Popovic</a> (Ph.D. Student)
		<br><a href="/people/ahalyaprabhakar">Ahalya Prabhakar</a> (Ph.D. Student)
		<br><a href="/people/millischlafly">Milli Schlafly</a> (Ph.D. Student)
		<br><a href="/people/annalisataylor">Annalisa Taylor</a> (Ph.D. Student) </p>

	<h3>Collaborators</h3>
	<p>Siemens</p>

	<h3>Publications</h3>
	<p><b>Real-time area coverage and target localization using receding-horizon ergodic exploration</b>
		<br>A. Mavrommati, E. Tzorakoleftherakis, I. Abraham, and T. D. Murphey
		<br><i>IEEE Transactions on Robotics</i>, vol. 34, no. 1, pp. 62–80, 2018. <a href="pdfs/2018TROMaTzAbMu.pdf">PDF</a>,  <a href="videos/2018TROMaTzAbMuExplorationVideos.mp4">Video 1</a>,  <a href="videos/2018TROMaTzAbMuLocalizationVideos.mp4">Video 2</a></p>

	<h3>Funding</h3>
	<p>This project is funded by DARPA: Interaction & Perception: Multi-Source Spectral Framework for Human-Swarm Collaboration.</p><br>

</body>
